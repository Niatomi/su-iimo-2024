{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))\n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))\n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        rng = np.random.default_rng(seed=0)\n",
    "        self.w = rng.normal(size=(dim, 1)) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "\n",
    "    def predict(self, x, probs=False):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "\n",
    "        x = x.dot(self.w) + self.b  # logits\n",
    "        p = sigmoid(x)  # probabilities\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "\n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        # y - np.array размернсоти [N]\n",
    "        #     Массив меток (правильных ответов).\n",
    "        assert len(x) == len(y), \\\n",
    "            \"Количество экземпляров в массиве X не равно количеству меток в массиве Y. \" + \\\n",
    "            f\"Полученные размеры: len(X) = {len(x)}, len(Y) = {len(y)}.\"\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "        # Алгоритм градиентного спуска.\n",
    "        # Минимизируется бинарная кросс-энтропия.\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Применение логистической регрессии (несбалансированные данные)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Создание и обучение логистической регрессии\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указание: производить нормализацию данных не нужно, это часть задания.\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x7f94b9dc2890>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте модель логистической регрессии и обучите её, используя метод fit.\n",
    "lr = LogisticRegression(x_train.shape[1])\n",
    "lr.fit(x_train, y_train, iters=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318181818181818"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получите предсказания на тестовой выборке и оцените точность модели,\n",
    "# используя accuracy_score из пакета SciKit-Learn.\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(\n",
    "    y_test,\n",
    "    lr.predict(x_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Анализ качества модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Допишите класс \"глупого классификатора\", что всегда предсказывает класс `0`.\n",
    "\n",
    "class DummyClassifier:\n",
    "    def __init__(self, dt=np.float32):\n",
    "        self.dt = dt\n",
    "\n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Должен возвращаться массив N предсказаний\n",
    "        return np.zeros(x.shape[0], dtype=self.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцените точность \"глупого классификатора\", объясните результат.\n",
    "dc = DummyClassifier()\n",
    "assert x_test.shape[0] == dc.predict(x_test).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте дополнительные метрики (f1-score, recall, precision) из пакета sklearn для анализа \"глупого классификатора\".\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score\n",
    ")\n",
    "\n",
    "\n",
    "def get_stats(model, x_test, y_test, avg='binary') -> tuple:\n",
    "    m = model\n",
    "    y_pred = m.predict(x_test).astype(np.bool)\n",
    "    f1 = f1_score(y_test, y_pred, average=avg)\n",
    "    recall = recall_score(y_test, y_pred, average=avg)\n",
    "    precision = precision_score(y_test, y_pred, average=avg)\n",
    "    print(f'{f1=}')\n",
    "    print(f'{recall=}')\n",
    "    print(f'{precision=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=np.float64(0.0)\n",
      "recall=np.float64(0.0)\n",
      "precision=np.float64(0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nia/.pyenv/versions/3.10.14/envs/ssau3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "get_stats(dc, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=np.float64(0.6341463414634146)\n",
      "recall=np.float64(0.65)\n",
      "precision=np.float64(0.6190476190476191)\n"
     ]
    }
   ],
   "source": [
    "# Используя те же метрики, проанализируйте обученную вами модель логистической регрессии.\n",
    "get_stats(lr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Общие термины\n",
      "Глупый классификатор - DC\n",
      "Корректный классификатор - LR\n",
      "\n",
      "\n",
      "# Precision\n",
      "\n",
      "DC классификатор нашёл 0 единиц\n",
      "LR классификатор нашёл 21 единиц\n",
      "\n",
      "Из которых правильно предсказанные:\n",
      "Для DC: 0\n",
      "Для LR: 13\n",
      "\n",
      "Соответственно метрика Precision:\n",
      "DC: dc_correct_ones/dc_ones=0\n",
      "LR: lr_correct_ones/lr_ones=0.6190476190476191\n",
      "\n",
      "\n",
      "# Recall\n",
      "\n",
      "Всего меток с единицей 20\n",
      "\n",
      "Из которых правильно предсказанные:\n",
      "Для DC: 0\n",
      "Для LR: 13\n",
      "\n",
      "Соответственно метрика Recall:\n",
      "DC: dc_recall_ones/total_ones=0.0\n",
      "LR: lr_recall_ones/total_ones=0.65\n",
      "\n",
      "\n",
      "# F1 \n",
      "DC: (2 * dc_precision * dc_recall) / (dc_precision + dc_recall)=0\n",
      "LR: (2 * lr_precision * lr_recall) / (lr_precision + lr_recall)=0.6341463414634146\n",
      "\n",
      "\n",
      "# Общий вывод\n",
      "Так как вышеописанные метрики расчитываются относительно единичного класса,\n",
      "то для DC классификатора метрики равны нулю, так как модель предсказывает всегда ноль\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Объясните результат, описав его комментариями в этой клетке.\n",
    "total_ones = 0\n",
    "\n",
    "dc_pred = dc.predict(x_test)\n",
    "dc_ones = 0\n",
    "dc_correct_ones = 0\n",
    "dc_recall_ones = 0\n",
    "\n",
    "lr_pred = lr.predict(x_test)\n",
    "lr_ones = 0\n",
    "lr_correct_ones = 0\n",
    "lr_recall_ones = 0\n",
    "\n",
    "for dc_y_pred, lr_y_pred, y_real in zip(dc_pred, lr_pred, y_test):\n",
    "    if dc_y_pred == 1:\n",
    "        dc_ones += 1\n",
    "        if dc_y_pred == y_real:\n",
    "            dc_correct_ones += 1\n",
    "    if lr_y_pred == 1:\n",
    "        lr_ones += 1\n",
    "        if lr_y_pred == y_real:\n",
    "            lr_correct_ones += 1\n",
    "    if y_real == 1:\n",
    "        total_ones += 1\n",
    "        if dc_y_pred == y_real:\n",
    "            dc_recall_ones += 1\n",
    "        if lr_y_pred == y_real:\n",
    "            lr_recall_ones += 1\n",
    "\n",
    "dc_precision = 0\n",
    "lr_precision = lr_correct_ones/lr_ones\n",
    "\n",
    "dc_recall = 0\n",
    "lr_recall = lr_recall_ones/total_ones\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "# Общие термины\n",
    "Глупый классификатор - DC\n",
    "Корректный классификатор - LR\n",
    "\n",
    "\n",
    "# Precision\n",
    "\n",
    "DC классификатор нашёл {dc_ones} единиц\n",
    "LR классификатор нашёл {lr_ones} единиц\n",
    "\n",
    "Из которых правильно предсказанные:\n",
    "Для DC: {dc_correct_ones}\n",
    "Для LR: {lr_correct_ones}\n",
    "\n",
    "Соответственно метрика Precision:\n",
    "DC: dc_correct_ones/dc_ones=0\n",
    "LR: {lr_correct_ones/lr_ones=}\n",
    "\n",
    "\n",
    "# Recall\n",
    "\n",
    "Всего меток с единицей {total_ones}\n",
    "\n",
    "Из которых правильно предсказанные:\n",
    "Для DC: {dc_recall_ones}\n",
    "Для LR: {lr_recall_ones}\n",
    "\n",
    "Соответственно метрика Recall:\n",
    "DC: {dc_recall_ones/total_ones=}\n",
    "LR: {lr_recall_ones/total_ones=}\n",
    "\n",
    "\n",
    "# F1 \n",
    "DC: (2 * dc_precision * dc_recall) / (dc_precision + dc_recall)=0\n",
    "LR: {(2 * lr_precision * lr_recall) / (lr_precision + lr_recall)=}\n",
    "\n",
    "\n",
    "# Общий вывод\n",
    "Так как вышеописанные метрики расчитываются относительно единичного класса,\n",
    "то для DC классификатора метрики равны нулю, так как модель предсказывает всегда ноль\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Анализ набора данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float32(0.0): 200, np.float32(1.0): 20}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посчитайте количество экземпляров данных для каждого класса.\n",
    "def count_classes(y_test):\n",
    "    total_count = {}\n",
    "    for y in set(y_test):\n",
    "        total_count[y] = len(y_test[np.where(\n",
    "            y_test == y\n",
    "        )])\n",
    "    return total_count\n",
    "\n",
    "\n",
    "count_classes(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предложите способ улучшения качества модели.\n",
    "# Подсказка: добавление дубликатов в данные.\n",
    "# Указание: не изменяйте тестовую выборку.\n",
    "def find_best_train(\n",
    "    x_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    dups_of_class: int = 0,\n",
    "    shuffle: bool = False,\n",
    "    seed: int = None\n",
    ") -> tuple[np.array, np.array]:\n",
    "    \"\"\"Досоздание данных для обучения\n",
    "\n",
    "    Args:\n",
    "        x_train (np.array размерности [N, dim]): \n",
    "            Массив входных признаков.\n",
    "        y_train (np.array размернсоти [N]): \n",
    "            Массив меток (правильных ответов).\n",
    "        shuffle (bool, optional): \n",
    "            Перемешивать данные или нет. \n",
    "            Defaults to False.\n",
    "        seed (int, optional): \n",
    "            Сид для перемешивания данных. \n",
    "            Defaults to None.\n",
    "        dups_of_class (int, optional): \n",
    "            Колличество дубликатов на каждый класс. \n",
    "            Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, np.array]:\n",
    "        Сбаланисированные массивы входных признаков и меток\n",
    "    \"\"\"\n",
    "\n",
    "    def get_intervals(ind):\n",
    "        return ind[0][0], ind[0][-1], len(ind[0])\n",
    "\n",
    "    if dups_of_class < 0:\n",
    "        raise Exception(\n",
    "            'Параметр дубликатов датасета должен быть не отрицательным числом')\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    xt, yt = x_train.copy(), y_train.copy()\n",
    "\n",
    "    total_count = count_classes(yt)\n",
    "    cnt = list(total_count.values())\n",
    "\n",
    "    ones_indicies = np.where(yt == 1)\n",
    "\n",
    "    low, high, _ = get_intervals(ones_indicies)\n",
    "    poses = np.random.randint(low=low, high=high, size=cnt[0] - cnt[1])\n",
    "\n",
    "    xt = np.vstack((xt, xt[poses]))\n",
    "    yt = np.hstack((yt, yt[poses]))\n",
    "\n",
    "    assert xt.shape[0] == yt.shape[0]\n",
    "\n",
    "    if dups_of_class:\n",
    "        ind = np.where(yt == 0)\n",
    "        low, high, _ = get_intervals(ind)\n",
    "        poses = np.random.randint(low=low, high=high, size=dups_of_class)\n",
    "        xt = np.vstack((xt[poses], xt))\n",
    "        yt = np.hstack((yt[poses], yt))\n",
    "        \n",
    "        ind = np.where(yt == 1)\n",
    "        low, high, _ = get_intervals(ind)\n",
    "        poses = np.random.randint(low=low, high=high, size=dups_of_class)\n",
    "        xt = np.vstack((xt, xt[poses]))\n",
    "        yt = np.hstack((yt, yt[poses]))\n",
    "\n",
    "    if shuffle:\n",
    "        idxs = np.arange(len(yt))\n",
    "        np.random.shuffle(idxs)\n",
    "        return xt[idxs], yt[idxs]\n",
    "    return xt, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old model\n",
      "f1=np.float64(0.6341463414634146)\n",
      "recall=np.float64(0.65)\n",
      "precision=np.float64(0.6190476190476191)\n",
      "------ ------\n",
      "New model\n",
      "f1=np.float64(0.7441860465116279)\n",
      "recall=np.float64(0.8)\n",
      "precision=np.float64(0.6956521739130435)\n"
     ]
    }
   ],
   "source": [
    "# Создайте и обучите модель с использованием предложенных наработок.\n",
    "xt, yt = find_best_train(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    dups_of_class=0,\n",
    "    shuffle=False,\n",
    "    seed=42424\n",
    ")\n",
    "bm = LogisticRegression(x_train.shape[1])\n",
    "bm.fit(xt, yt)\n",
    "\n",
    "\n",
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics.\n",
    "# Указание: постарайтесь сбалансировать данные таким образом, чтобы новая модель была ощутимо лучше старой.\n",
    "print('Old model')\n",
    "get_stats(lr, x_test, y_test)\n",
    "print('------ ------')\n",
    "print('New model')\n",
    "get_stats(bm, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Применение логистической регрессии (нелинейные данные)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x7f94b9dc3730>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель но на этом наборе данных.\n",
    "lr = LogisticRegression(x_train.shape[1])\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=np.float64(0.6194690265486725)\n",
      "recall=np.float64(0.7777777777777778)\n",
      "precision=np.float64(0.5147058823529411)\n"
     ]
    }
   ],
   "source": [
    "# Проанализируйте качество модели.\n",
    "get_stats(lr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: попробуйте применить на исходных данных разные нелинейные функции (sin, tanh, ...).\n",
    "# Объедините трансформированные данные с исходными (важно: количество экземпляров в x_train не должно увеличиться).\n",
    "x_train, y_train, x_test, y_test = load_data('dataset2')\n",
    "\n",
    "\n",
    "OPS = [\n",
    "    np.sin,\n",
    "    np.cos,\n",
    "    np.tan,\n",
    "]\n",
    "\n",
    "\n",
    "def apply_ops(\n",
    "    x_train: np.ndarray,\n",
    "    ops: list[np.ufunc]\n",
    ") -> np.ndarray:\n",
    "    xt = x_train.copy()\n",
    "    input_size = xt.shape[0]\n",
    "    for op in ops:\n",
    "        assert type(op) is np.ufunc\n",
    "        xt = np.hstack(\n",
    "            (xt, op(xt))\n",
    "        )\n",
    "    assert input_size == xt.shape[0]\n",
    "    return xt\n",
    "\n",
    "\n",
    "x_train = apply_ops(x_train, OPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x7f94b9dc1d80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель с использованием наработок.\n",
    "lr = LogisticRegression(x_train.shape[1])\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=np.float64(1.0)\n",
      "recall=np.float64(1.0)\n",
      "precision=np.float64(1.0)\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics.\n",
    "# Указание: постарайтесь добиться точности в 100%!\n",
    "get_stats(lr, apply_ops(x_test, OPS), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Доп. задания (любое на выбор, опционально)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 'Обобщение' логистической регрессии\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите многоклассовый классификатор. Обучите его на наборе данных ниже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ансамбль логистических регрессий.</b> Сложность: супергерой.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс, что инкапсулирует в себе `C` логистических регрессий, \n",
    "где `C` - количество классов. i-ая логистическая регрессия производит \n",
    "бинарную классификацию вида: все остальные классы и i-ый класс.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MulticlassLogisticRegression:\n",
    "\n",
    "    def __init__(self, n_classes, dim):\n",
    "        self.regressions: dict[int, LogisticRegression] = {}\n",
    "        for c in range(n_classes):\n",
    "            self.regressions[c] = LogisticRegression(dim)\n",
    "        self.default_predict_class = 0\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        x: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (np.ndarray) [N, dim]:\n",
    "                Массив входных признаков.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray:\n",
    "                Возвращается массив целых чисел размерности [N],\n",
    "                где i-ый элемент обозначает номер класса для\n",
    "                i-го экземпляра данных в `x`.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for model in self.regressions.values():\n",
    "            data.append(model.predict(x, probs=True))\n",
    "\n",
    "        result = np.zeros(x.shape[0])\n",
    "        for r_idx in range(x.shape[0]):\n",
    "            decided_class = self.default_predict_class\n",
    "            max_prob = 0\n",
    "            for model_idx, model_value in enumerate(self.regressions.keys()):\n",
    "                if data[model_idx][r_idx][0] >= max_prob:\n",
    "                    decided_class = model_value\n",
    "                    max_prob = data[model_idx][r_idx][0]\n",
    "            result[r_idx] = decided_class\n",
    "        return result.astype('int32')\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ):\n",
    "        for c in set(y):\n",
    "            if c not in self.regressions.keys():\n",
    "                raise Exception('Неизвестный класс')\n",
    "        for c in self.regressions.keys():\n",
    "            prepared_y = np.zeros_like(y)\n",
    "            cls = np.where(\n",
    "                c == y\n",
    "            )\n",
    "            prepared_y[cls] = 1\n",
    "            plr = self.regressions[c]\n",
    "            plr.fit(x, prepared_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        48\n",
      "           1       0.90      0.97      0.94        39\n",
      "           2       0.98      1.00      0.99        52\n",
      "           3       0.94      0.96      0.95        49\n",
      "           4       1.00      0.90      0.95        39\n",
      "           5       0.88      1.00      0.93        50\n",
      "           6       0.93      0.98      0.95        42\n",
      "           7       0.89      0.98      0.93        43\n",
      "           8       0.92      0.59      0.72        37\n",
      "           9       0.92      0.92      0.92        51\n",
      "\n",
      "    accuracy                           0.94       450\n",
      "   macro avg       0.94      0.93      0.93       450\n",
      "weighted avg       0.94      0.94      0.93       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создайте и обучите написанный классификатор.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_data('dataset3')\n",
    "mlr = MulticlassLogisticRegression(\n",
    "    n_classes=len(set(y_train)),\n",
    "    dim=x_train.shape[1]\n",
    ")\n",
    "mlr.fit(x_train, y_train)\n",
    "y_predicted = mlr.predict(x_test)\n",
    "\n",
    "# Оцените точность модели.\n",
    "LABELS = list(set(y_train))\n",
    "print(classification_report(y_test, y_predicted, labels=LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssau3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
