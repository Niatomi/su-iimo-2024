{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    x_train = np.load(os.path.join(folder_path, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder_path, 'y_train.npy'))\n",
    "    x_test = np.load(os.path.join(folder_path, 'x_test.npy'))\n",
    "    y_test = np.load(os.path.join(folder_path, 'y_test.npy'))\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('lr4_dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной лабораторной работе будет практиковаться поиск гиперпараметров. Буду рассмотрены алгоритмы поиска гиперпараметров: grid search, random search.\n",
    "\n",
    "Помимо поиска гиперпараметров будет рассмотрен алгоритм кросс-валидации, позволяющий получить более достоверную оценку качества модели в условиях недостатка данных.\n",
    "Хотя в работе предоставлена тестовая выборка, здесь она имеет сугубо теоретический характер (для получения финальной оценки) и на практике как правило недоступна. Поэтому во время подбора гиперпараметров используются лишь `x_train, y_train`. `x_test, y_test` используются лишь для получения финальной оценки, чтобы можно было видеть разницу между разными алгоритмами подбора гиперпараметров (если она будет).\n",
    "\n",
    "Выберите одну модель из списка: MLPClassifier, SGDClassifier, DecisionTreeClassifier, RandomForestClassifier, SVC.\n",
    "Для выбранной модели произведите поиск оптимальных гиперпараметров.\n",
    "\n",
    "**Требование**: поиск должен идти как минимум для двух гиперпараметров.\n",
    "\n",
    "**Требование**: в конструктор моделей передавайте `random_state=1` для воспроизводимости результатов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Обучение бейзлайн модели для проведения сравнения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.50      0.33      0.40         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.50      0.33      0.40         3\n",
      "           7       0.50      1.00      0.67         3\n",
      "           8       0.67      0.67      0.67         3\n",
      "           9       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.57      0.63      0.58        30\n",
      "weighted avg       0.57      0.63      0.58        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Обучите базовую модель без изменения гиперпараметров (т.е. используются гиперпараметры по умолчанию).\n",
    "base_model = RandomForestClassifier(random_state=1)\n",
    "base_model.fit(x_train, y_train)\n",
    "y_pred = base_model.predict(x_test)\n",
    "# Проанализируйте качество модели (accuracy, матрица ошибок).\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Fold Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте фунцию кросс-валидации\n",
    "# Замечание: x_test, y_test не должны применятся в рамках данной функции.\n",
    "from typing import Callable\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "def kfold_cv(\n",
    "        model_fn: Callable,\n",
    "        eval_fn: Callable[[np.ndarray, np.ndarray], float],\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        n_splits: int = 5) -> float:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_fn : callable\n",
    "        Функция-фабрика, что конструирует и возвращает новый объект модели.\n",
    "        Например: `lambda: MLPClassifier(hidden_layer_sizes=(256,))`.\n",
    "    eval_fn : callable\n",
    "        Функция вида `eval_fn(labels, predictions)`, что возвращает скаляр (значение метрики).\n",
    "    x : np.ndarray\n",
    "        Набор признаков (размерность NxD, N - количество экземпляров, D - количество признаков).\n",
    "    y : np.ndarray\n",
    "        Набор меток (размерность N)\n",
    "    n_splits : int, optional\n",
    "        Количество фолдов (подвыборок), по умолчанию 5.\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Среднее значение метрики (что вычисляется eval_fn) по фолдам.\n",
    "    \"\"\"\n",
    "    assert x.shape[0] == y.shape[0], 'Входные данные отличаются по колличеству'\n",
    "\n",
    "    def get_splits(i: int) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        x_split: list = np.split(x.copy(), n_splits)\n",
    "        y_split: list = np.split(y.copy(), n_splits)\n",
    "        test_x = x_split.pop(i)\n",
    "        test_y = y_split.pop(i)\n",
    "        return (np.vstack(x_split), np.vstack(y_split).flatten(), test_x, test_y)\n",
    "\n",
    "    metrics_vals = []\n",
    "    for idx in range(n_splits):\n",
    "        _x_train, _y_train, _x_test, _y_test = get_splits(idx)\n",
    "        model = model_fn()\n",
    "        model.fit(_x_train, _y_train)\n",
    "        predictions = model.predict(_x_test)\n",
    "        metrics_vals.append(eval_fn(_y_test, predictions))\n",
    "    return mean(metrics_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3909090909090909"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Убедитесь в корректности работы функции кросс-валидации.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "kfold_cv(\n",
    "    lambda: RandomForestClassifier(random_state=1),\n",
    "    accuracy_score,\n",
    "    x_train,\n",
    "    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from time import time\n",
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=max_depth)\n",
      "        Execution time: 0.13 \n",
      "        Best metric: best_metric=0.25 \n",
      "        Result: {'n_estimators': 10, 'max_depth': 100}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=min_samples_split)\n",
      "        Execution time: 0.31 \n",
      "        Best metric: best_metric=0.16 \n",
      "        Result: {'n_estimators': 10, 'min_samples_split': 20}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=min_samples_leaf)\n",
      "        Execution time: 0.53 \n",
      "        Best metric: best_metric=0.13 \n",
      "        Result: {'n_estimators': 10, 'min_samples_leaf': 10}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=min_weight_fraction_leaf)\n",
      "        Execution time: 0.95 \n",
      "        Best metric: best_metric=0.25 \n",
      "        Result: {'n_estimators': 10, 'min_weight_fraction_leaf': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=min_impurity_decrease)\n",
      "        Execution time: 1.26 \n",
      "        Best metric: best_metric=0.25 \n",
      "        Result: {'n_estimators': 10, 'min_impurity_decrease': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=ccp_alpha)\n",
      "        Execution time: 2.12 \n",
      "        Best metric: best_metric=0.25 \n",
      "        Result: {'n_estimators': 10, 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=max_depth)\n",
      "        Execution time: 3.27 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'max_depth': 100}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=max_depth)\n",
      "        Execution time: 3.44 \n",
      "        Best metric: best_metric=0.29 \n",
      "        Result: {'min_samples_leaf': 10, 'max_depth': 100}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=max_depth)\n",
      "        Execution time: 4.07 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_impurity_decrease': 0.0001, 'max_depth': 100}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=max_depth)\n",
      "        Execution time: 4.42 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_weight_fraction_leaf': 0.0001, 'max_depth': 100}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=max_depth)\n",
      "        Execution time: 4.62 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'max_features': 'sqrt', 'max_depth': 100}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=min_samples_split)\n",
      "        Execution time: 6.38 \n",
      "        Best metric: best_metric=0.29 \n",
      "        Result: {'min_samples_leaf': 10, 'min_samples_split': 20}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_depth,p1=warm_start)\n",
      "        Execution time: 7.41 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'max_depth': 100, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_depth,p1=bootstrap)\n",
      "        Execution time: 8.50 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_depth': 100, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_depth,p1=min_samples_split)\n",
      "        Execution time: 8.73 \n",
      "        Best metric: best_metric=0.35 \n",
      "        Result: {'max_depth': 100, 'min_samples_split': 20}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=min_samples_split)\n",
      "        Execution time: 8.98 \n",
      "        Best metric: best_metric=0.35 \n",
      "        Result: {'min_impurity_decrease': 0.0001, 'min_samples_split': 20}\n",
      "        ----------------------------\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=min_weight_fraction_leaf)\n",
      "        Execution time: 9.41 \n",
      "        Best metric: best_metric=0.29 \n",
      "        Result: {'min_samples_leaf': 10, 'min_weight_fraction_leaf': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=min_samples_split)\n",
      "        Execution time: 9.53 \n",
      "        Best metric: best_metric=0.35 \n",
      "        Result: {'criterion': 'gini', 'min_samples_split': 20}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=min_samples_split)\n",
      "        Execution time: 9.68 \n",
      "        Best metric: best_metric=0.35 \n",
      "        Result: {'min_weight_fraction_leaf': 0.0001, 'min_samples_split': 20}\n",
      "        ----------------------------\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=min_samples_split)\n",
      "        Execution time: 9.61 \n",
      "        Best metric: best_metric=0.35 \n",
      "        Result: {'max_features': 'sqrt', 'min_samples_split': 20}\n",
      "        ----------------------------\n",
      "\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=min_samples_leaf)\n",
      "        Execution time: 11.32 \n",
      "        Best metric: best_metric=0.29 \n",
      "        Result: {'criterion': 'gini', 'min_samples_leaf': 10}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=min_weight_fraction_leaf)\n",
      "        Execution time: 12.60 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'min_weight_fraction_leaf': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=bootstrap,p1=warm_start)\n",
      "        Execution time: 12.20 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'bootstrap': False, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=min_impurity_decrease)\n",
      "        Execution time: 13.05 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'min_impurity_decrease': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=min_impurity_decrease)\n",
      "        Execution time: 14.10 \n",
      "        Best metric: best_metric=0.29 \n",
      "        Result: {'min_samples_leaf': 10, 'min_impurity_decrease': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=ccp_alpha)\n",
      "        Execution time: 14.47 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=min_impurity_decrease)\n",
      "        Execution time: 14.34 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'max_features': 'sqrt', 'min_impurity_decrease': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=min_impurity_decrease)\n",
      "        Execution time: 14.60 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_weight_fraction_leaf': 0.0001, 'min_impurity_decrease': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_split,p1=bootstrap)\n",
      "        Execution time: 14.26 \n",
      "        Best metric: best_metric=0.35 \n",
      "        Result: {'min_samples_split': 20, 'bootstrap': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=ccp_alpha)\n",
      "        Execution time: 14.86 \n",
      "        Best metric: best_metric=0.29 \n",
      "        Result: {'min_samples_leaf': 10, 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_split,p1=ccp_alpha)\n",
      "        Execution time: 14.38 \n",
      "        Best metric: best_metric=0.35 \n",
      "        Result: {'min_samples_split': 20, 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=bootstrap,p1=ccp_alpha)\n",
      "        Execution time: 14.52 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'bootstrap': True, 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_split,p1=warm_start)\n",
      "        Execution time: 15.14 \n",
      "        Best metric: best_metric=0.35 \n",
      "        Result: {'min_samples_split': 20, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=ccp_alpha)\n",
      "        Execution time: 15.46 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_impurity_decrease': 0.0001, 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=warm_start)\n",
      "        Execution time: 16.48 \n",
      "        Best metric: best_metric=0.29 \n",
      "        Result: {'min_samples_leaf': 10, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_depth,p1=ccp_alpha)\n",
      "        Execution time: 16.09 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'max_depth': 100, 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=ccp_alpha)\n",
      "        Execution time: 16.44 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_weight_fraction_leaf': 0.0001, 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=bootstrap)\n",
      "        Execution time: 16.62 \n",
      "        Best metric: best_metric=0.29 \n",
      "        Result: {'min_samples_leaf': 10, 'bootstrap': True}\n",
      "        ----------------------------\n",
      "\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=ccp_alpha)\n",
      "        Execution time: 16.38 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'max_features': 'sqrt', 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=warm_start,p1=ccp_alpha)\n",
      "        Execution time: 16.19 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'warm_start': True, 'ccp_alpha': 0.0001}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=warm_start)\n",
      "        Execution time: 18.05 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=bootstrap)\n",
      "        Execution time: 18.16 \n",
      "        Best metric: best_metric=0.45 \n",
      "        Result: {'criterion': 'entropy', 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=bootstrap)\n",
      "        Execution time: 19.40 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'min_weight_fraction_leaf': 0.0001, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=bootstrap)\n",
      "        Execution time: 19.25 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'min_impurity_decrease': 0.0001, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=warm_start)\n",
      "        Execution time: 19.56 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_weight_fraction_leaf': 0.0001, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=warm_start)\n",
      "        Execution time: 20.63 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_impurity_decrease': 0.0001, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=max_features)\n",
      "        Execution time: 22.11 \n",
      "        Best metric: best_metric=0.33 \n",
      "        Result: {'min_samples_leaf': 10, 'max_features': None}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=warm_start)\n",
      "        Execution time: 23.10 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_features': None, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=bootstrap)\n",
      "        Execution time: 23.25 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_features': 'sqrt', 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=max_features)\n",
      "        Execution time: 29.73 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'min_weight_fraction_leaf': 0.0001, 'max_features': None}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=warm_start)\n",
      "        Execution time: 30.42 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=bootstrap)\n",
      "        Execution time: 30.70 \n",
      "        Best metric: best_metric=0.45 \n",
      "        Result: {'n_estimators': 1000, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=max_features)\n",
      "        Execution time: 31.61 \n",
      "        Best metric: best_metric=0.45 \n",
      "        Result: {'criterion': 'entropy', 'max_features': None}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=criterion)\n",
      "        Execution time: 40.67 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'criterion': 'gini'}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=max_features)\n",
      "        Execution time: 59.23 \n",
      "        Best metric: best_metric=0.46 \n",
      "        Result: {'n_estimators': 1000, 'max_features': None}\n",
      "        ----------------------------\n",
      "Total processing time 59.27531838417053\n"
     ]
    }
   ],
   "source": [
    "# 1. Реализуйте алгоритм поиска гиперпараметров grid search.\n",
    "# 2. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "# 3. Выведите найденные значения гиперпараметров и время работы.\n",
    "# Замечание: x_test, y_test не должны применятся в рамках данного алгоритма.\n",
    "# Замечание: убедитесь, что гиперпараметры по умолчанию включены в пространство поиска.\n",
    "# Требование: используйте kfold_cv для получения значения метрики в рамках одной итерации поиска гиперпараметров.\n",
    "\n",
    "\n",
    "def log10_range(_from, _to):\n",
    "    if _from == 0:\n",
    "        raise Exception('Начальное значение не может быть нулём')\n",
    "    while _from < _to:\n",
    "        _from *= 10\n",
    "        yield _from\n",
    "\n",
    "\n",
    "def kfold_grid_search_worker(\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        model_class,\n",
    "        eval_fn: Callable[[np.ndarray, np.ndarray], float],\n",
    "        param1: str,\n",
    "        param2: str,\n",
    "        param_space: dict[str, Iterable],\n",
    "        rmlist: list):\n",
    "    t1 = time()\n",
    "    best_metric = 0.0\n",
    "    best_params = {}\n",
    "    for p1 in param_space[param1]:\n",
    "        for p2 in param_space[param2]:\n",
    "            params = {\n",
    "                param1: p1,\n",
    "                param2: p2\n",
    "            }\n",
    "            metric = kfold_cv(\n",
    "                lambda: model_class(random_state=1, **params),\n",
    "                eval_fn,\n",
    "                x,\n",
    "                y\n",
    "            )\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_params = params\n",
    "    t1 = time() - t1\n",
    "    print(\n",
    "        f\"\"\"\n",
    "        ----------------------------\n",
    "        Worker(p1={param1},p1={param2})\n",
    "        Execution time: {t1:.2f} \n",
    "        Best metric: {best_metric=:.2f} \n",
    "        Result: {best_params}\n",
    "        ----------------------------\"\"\"\n",
    "    )\n",
    "    rmlist.append((best_metric, best_params))\n",
    "\n",
    "\n",
    "def kfold_grid_search(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    model_class,\n",
    "    eval_fn: Callable[[np.ndarray, np.ndarray], float],\n",
    "    param_space: dict[str, Iterable],\n",
    "):\n",
    "    divided = []\n",
    "    for key1, _ in param_space.items():\n",
    "        for key2, _ in param_space.items():\n",
    "            if key1 == key2:\n",
    "                continue\n",
    "            if (key1, key2) in divided or \\\n",
    "                    (key2, key1) in divided:\n",
    "                continue\n",
    "            divided.append((key1, key2))\n",
    "    result_manager = Manager()\n",
    "    rmlist = result_manager.list()\n",
    "    ps = [\n",
    "        Process(\n",
    "            target=kfold_grid_search_worker,\n",
    "            args=(x, y, model_class, eval_fn, param1, param2, param_space, rmlist,))\n",
    "        for param1, param2 in divided\n",
    "    ]\n",
    "    t1 = time()\n",
    "    [p.start() for p in ps]\n",
    "    [p.join() for p in ps]\n",
    "    print(f'Total processing time {time() - t1}')\n",
    "    merged_params = {}\n",
    "    for _, params in list(reversed(sorted(list(rmlist), key=lambda tup: tup[0]))):\n",
    "        for key, value in params.items():\n",
    "            cur = merged_params.get(key, None)\n",
    "            if cur is None:\n",
    "                merged_params[key] = value\n",
    "    return merged_params\n",
    "\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': log10_range(1, 1000),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_leaf': log10_range(1, 10 ** 4),\n",
    "    'min_weight_fraction_leaf': log10_range(10 ** -5, 0.1),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_impurity_decrease': log10_range(10 ** -5, 1),\n",
    "    'max_depth': log10_range(10, 100),\n",
    "    'min_samples_split': log10_range(2, 1000),\n",
    "    'bootstrap': [True, False],\n",
    "    'warm_start': [True, False],\n",
    "    'ccp_alpha': log10_range(10 ** -5, 1),\n",
    "}\n",
    "\n",
    "found_params = kfold_grid_search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    RandomForestClassifier,\n",
    "    accuracy_score,\n",
    "    param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False,\n",
      " 'ccp_alpha': 0.0001,\n",
      " 'criterion': 'entropy',\n",
      " 'max_depth': 100,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_impurity_decrease': 0.0001,\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 20,\n",
      " 'min_weight_fraction_leaf': 0.0001,\n",
      " 'n_estimators': 1000,\n",
      " 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(found_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.50      0.33      0.40         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.50      0.33      0.40         3\n",
      "           7       0.50      1.00      0.67         3\n",
      "           8       0.67      0.67      0.67         3\n",
      "           9       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.57      0.63      0.58        30\n",
      "weighted avg       0.57      0.63      0.58        30\n",
      "\n",
      "Found params model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.50      0.67      0.57         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       0.50      1.00      0.67         3\n",
      "           8       1.00      0.33      0.50         3\n",
      "           9       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.81      0.73      0.72        30\n",
      "weighted avg       0.81      0.73      0.72        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели.\n",
    "# Протестируйте модель на x_test, y_test.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "new_model = RandomForestClassifier(random_state=1, **found_params)\n",
    "new_model.fit(x_train, y_train)\n",
    "\n",
    "print('Base model')\n",
    "y_pred = base_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print('Found params model')\n",
    "y_pred = new_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=warm_start)\n",
      "        Execution time: 13.48 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_samples_leaf': 1, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=bootstrap)\n",
      "        Execution time: 13.59 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'min_impurity_decrease': 1e-05, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_split,p1=bootstrap)\n",
      "        Execution time: 13.88 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'min_samples_split': 2, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=warm_start)\n",
      "        Execution time: 14.61 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_weight_fraction_leaf': 1e-05, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_split,p1=warm_start)\n",
      "        Execution time: 14.58 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_samples_split': 2, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=warm_start,p1=ccp_alpha)\n",
      "        Execution time: 14.47 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'warm_start': True, 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=bootstrap,p1=warm_start)\n",
      "        Execution time: 14.77 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'bootstrap': False, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=min_impurity_decrease)\n",
      "        Execution time: 15.70 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_samples_leaf': 1, 'min_impurity_decrease': 1e-05}\n",
      "        ----------------------------\n",
      "        ----------------------------\n",
      "        Worker(p1=max_depth,p1=min_samples_split)\n",
      "        Execution time: 15.18 \n",
      "        Best metric: best_metric=0.41 \n",
      "        Result: {'max_depth': 10, 'min_samples_split': 2}\n",
      "        ----------------------------\n",
      "\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=min_samples_split)\n",
      "        Execution time: 15.86 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=bootstrap)\n",
      "        Execution time: 15.88 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'min_weight_fraction_leaf': 1e-05, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=bootstrap)\n",
      "        Execution time: 16.01 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'min_samples_leaf': 1, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=min_impurity_decrease)\n",
      "        Execution time: 15.98 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_weight_fraction_leaf': 1e-05, 'min_impurity_decrease': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=min_weight_fraction_leaf)\n",
      "        Execution time: 16.35 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_samples_leaf': 1, 'min_weight_fraction_leaf': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=min_samples_split)\n",
      "        Execution time: 16.37 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_weight_fraction_leaf': 1e-05, 'min_samples_split': 2}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=max_depth)\n",
      "        Execution time: 16.53 \n",
      "        Best metric: best_metric=0.41 \n",
      "        Result: {'min_samples_leaf': 1, 'max_depth': 10}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=min_samples_split)\n",
      "        Execution time: 16.42 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_impurity_decrease': 1e-05, 'min_samples_split': 2}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=ccp_alpha)\n",
      "        Execution time: 16.36 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_impurity_decrease': 1e-05, 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=warm_start)\n",
      "        Execution time: 16.68 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_impurity_decrease': 1e-05, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_depth,p1=bootstrap)\n",
      "        Execution time: 16.73 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_depth': 100, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=max_depth)\n",
      "        Execution time: 17.22 \n",
      "        Best metric: best_metric=0.41 \n",
      "        Result: {'min_weight_fraction_leaf': 1e-05, 'max_depth': 10}\n",
      "        ----------------------------\n",
      "\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_impurity_decrease,p1=max_depth)\n",
      "        Execution time: 17.06 \n",
      "        Best metric: best_metric=0.41 \n",
      "        Result: {'min_impurity_decrease': 1e-05, 'max_depth': 10}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=min_samples_split)\n",
      "        Execution time: 17.63 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'min_samples_split': 2}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=ccp_alpha)\n",
      "        Execution time: 17.52 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_samples_leaf': 1, 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=bootstrap,p1=ccp_alpha)\n",
      "        Execution time: 16.80 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'bootstrap': False, 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_depth,p1=warm_start)\n",
      "        Execution time: 17.61 \n",
      "        Best metric: best_metric=0.41 \n",
      "        Result: {'max_depth': 10, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=ccp_alpha)\n",
      "        Execution time: 18.17 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_weight_fraction_leaf': 1e-05, 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_split,p1=ccp_alpha)\n",
      "        Execution time: 17.82 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'min_samples_split': 2, 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_depth,p1=ccp_alpha)\n",
      "        Execution time: 18.38 \n",
      "        Best metric: best_metric=0.41 \n",
      "        Result: {'max_depth': 10, 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=min_weight_fraction_leaf)\n",
      "        Execution time: 20.21 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'min_weight_fraction_leaf': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=min_impurity_decrease)\n",
      "        Execution time: 20.75 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'min_impurity_decrease': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=min_samples_leaf)\n",
      "        Execution time: 21.33 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'min_samples_leaf': 1}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=max_depth)\n",
      "        Execution time: 22.18 \n",
      "        Best metric: best_metric=0.41 \n",
      "        Result: {'criterion': 'gini', 'max_depth': 10}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=ccp_alpha)\n",
      "        Execution time: 22.59 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=bootstrap)\n",
      "        Execution time: 23.59 \n",
      "        Best metric: best_metric=0.45 \n",
      "        Result: {'criterion': 'entropy', 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=warm_start)\n",
      "        Execution time: 24.54 \n",
      "        Best metric: best_metric=0.39 \n",
      "        Result: {'criterion': 'gini', 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_samples_leaf,p1=max_features)\n",
      "        Execution time: 25.07 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'min_samples_leaf': 1, 'max_features': None}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=min_samples_split)\n",
      "        Execution time: 25.70 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_features': None, 'min_samples_split': 2}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=min_impurity_decrease)\n",
      "        Execution time: 26.77 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_features': None, 'min_impurity_decrease': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=min_weight_fraction_leaf,p1=max_features)\n",
      "        Execution time: 27.69 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'min_weight_fraction_leaf': 1e-05, 'max_features': None}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=ccp_alpha)\n",
      "        Execution time: 28.72 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_features': None, 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=max_depth)\n",
      "        Execution time: 29.15 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_features': None, 'max_depth': 100}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=warm_start)\n",
      "        Execution time: 29.09 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_features': None, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=max_features,p1=bootstrap)\n",
      "        Execution time: 31.54 \n",
      "        Best metric: best_metric=0.43 \n",
      "        Result: {'max_features': 'sqrt', 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=min_impurity_decrease)\n",
      "        Execution time: 34.03 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'min_impurity_decrease': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=min_weight_fraction_leaf)\n",
      "        Execution time: 34.46 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'min_weight_fraction_leaf': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=warm_start)\n",
      "        Execution time: 35.01 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'warm_start': True}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=min_samples_split)\n",
      "        Execution time: 35.07 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'min_samples_split': 2}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=min_samples_leaf)\n",
      "        Execution time: 36.24 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'min_samples_leaf': 1}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=bootstrap)\n",
      "        Execution time: 36.41 \n",
      "        Best metric: best_metric=0.45 \n",
      "        Result: {'n_estimators': 1000, 'bootstrap': False}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=max_depth)\n",
      "        Execution time: 36.65 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'max_depth': 100}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=ccp_alpha)\n",
      "        Execution time: 37.40 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'ccp_alpha': 1e-05}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=criterion,p1=max_features)\n",
      "        Execution time: 38.89 \n",
      "        Best metric: best_metric=0.45 \n",
      "        Result: {'criterion': 'entropy', 'max_features': None}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=criterion)\n",
      "        Execution time: 47.37 \n",
      "        Best metric: best_metric=0.42 \n",
      "        Result: {'n_estimators': 1000, 'criterion': 'gini'}\n",
      "        ----------------------------\n",
      "\n",
      "        ----------------------------\n",
      "        Worker(p1=n_estimators,p1=max_features)\n",
      "        Execution time: 62.75 \n",
      "        Best metric: best_metric=0.46 \n",
      "        Result: {'n_estimators': 1000, 'max_features': None}\n",
      "        ----------------------------\n",
      "Total processing time 62.78893542289734\n"
     ]
    }
   ],
   "source": [
    "# 1. Реализуйте алгоритм поиска гиперпараметров random search.\n",
    "# 2. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "# 3. Выведите найденные значения гиперпараметров и время работы.\n",
    "# Замечание: x_test, y_test не должны применятся в рамках данного алгоритма.\n",
    "# Замечание: убедитесь, что гиперпараметры по умолчанию включены в пространство поиска.\n",
    "# Требование: используйте kfold_cv для получения значения метрики в рамках одной итерации поиска гиперпараметров.\n",
    "# Требование: количество итераций должно быть меньше в сравнении с grid search.\n",
    "from random import uniform, randint, getrandbits\n",
    "import sys\n",
    "\n",
    "# Максимальное колличество итераций для предыдущей модели\n",
    "# ccp_alpha X min_impurity_decrease = 5 X 5 = 25\n",
    "N_ITERS = 24\n",
    "\n",
    "\n",
    "def kfold_random_search_worker(\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        model_class,\n",
    "        eval_fn: Callable[[np.ndarray, np.ndarray], float],\n",
    "        param1: str,\n",
    "        param2: str,\n",
    "        param_space: dict[str, Iterable],\n",
    "        rmlist: list):\n",
    "    t1 = time()\n",
    "    best_metric = 0.0\n",
    "    best_params = {}\n",
    "\n",
    "    params_count = 0\n",
    "    for p1 in param_space[param1]:\n",
    "        for p2 in param_space[param2]:\n",
    "            params_count += 1\n",
    "\n",
    "    if params_count < N_ITERS:\n",
    "        for p1 in param_space[param1]:\n",
    "            for p2 in param_space[param2]:\n",
    "                params = {\n",
    "                    param1: p1,\n",
    "                    param2: p2\n",
    "                }\n",
    "                metric = kfold_cv(\n",
    "                    lambda: model_class(random_state=1, **params),\n",
    "                    eval_fn,\n",
    "                    x,\n",
    "                    y\n",
    "                )\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_params = params\n",
    "    else:\n",
    "        def get_typed_vlue(p0, iter):\n",
    "            if isinstance(p0, str):\n",
    "                return list(iter)[randint[0, len(iter) - 1]]\n",
    "            if isinstance(p0, int):\n",
    "                return randint(min(iter), max(iter))\n",
    "            if isinstance(p0, float):\n",
    "                return uniform(min(iter), max(iter))\n",
    "            if isinstance(p1, bool):\n",
    "                return bool(getrandbits(1))\n",
    "\n",
    "        def gen_random_params():\n",
    "            p1_iter = param_space[param1]\n",
    "            p2_iter = param_space[param2]\n",
    "            p01 = list(p1_iter)[0]\n",
    "            p02 = list(p1_iter)[0]\n",
    "            p1 = get_typed_vlue(p01, p1_iter)\n",
    "            p2 = get_typed_vlue(p02, p2_iter)\n",
    "            return p1, p2\n",
    "\n",
    "        for _ in range(N_ITERS):\n",
    "            p1, p2 = gen_random_params()\n",
    "            params = {\n",
    "                param1: p1,\n",
    "                param2: p2\n",
    "            }\n",
    "            metric = kfold_cv(\n",
    "                lambda: model_class(random_state=1, **params),\n",
    "                eval_fn,\n",
    "                x,\n",
    "                y\n",
    "            )\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_params = params\n",
    "    t1 = time() - t1\n",
    "    print(\n",
    "        f\"\"\"\n",
    "        ----------------------------\n",
    "        Worker(p1={param1},p1={param2})\n",
    "        Execution time: {t1:.2f} \n",
    "        Best metric: {best_metric=:.2f} \n",
    "        Result: {best_params}\n",
    "        ----------------------------\"\"\"\n",
    "    )\n",
    "    rmlist.append((best_metric, best_params))\n",
    "\n",
    "\n",
    "def kfold_random_search(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    model_class,\n",
    "    eval_fn: Callable[[np.ndarray, np.ndarray], float],\n",
    "    param_space: dict[str, Iterable],\n",
    "):\n",
    "    divided = []\n",
    "    for key1, _ in param_space.items():\n",
    "        for key2, _ in param_space.items():\n",
    "            if key1 == key2:\n",
    "                continue\n",
    "            if (key1, key2) in divided or \\\n",
    "                    (key2, key1) in divided:\n",
    "                continue\n",
    "            divided.append((key1, key2))\n",
    "    result_manager = Manager()\n",
    "    rmlist = result_manager.list()\n",
    "    ps = [\n",
    "        Process(\n",
    "            target=kfold_random_search_worker,\n",
    "            args=(x, y, model_class, eval_fn, param1, param2, param_space, rmlist,))\n",
    "        for param1, param2 in divided\n",
    "    ]\n",
    "    t1 = time()\n",
    "    [p.start() for p in ps]\n",
    "    [p.join() for p in ps]\n",
    "    print(f'Total processing time {time() - t1}')\n",
    "    merged_params = {}\n",
    "    for _, params in list(reversed(sorted(list(rmlist), key=lambda tup: tup[0]))):\n",
    "        for key, value in params.items():\n",
    "            cur = merged_params.get(key, None)\n",
    "            if cur is None:\n",
    "                merged_params[key] = value\n",
    "    return merged_params\n",
    "\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': (1, 1000),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_leaf': (1, 10 ** 4),\n",
    "    'min_weight_fraction_leaf': (10 ** -5, 0.1),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_impurity_decrease': (10 ** -5, 1),\n",
    "    'max_depth': (10, 100),\n",
    "    'min_samples_split': (2, 1000),\n",
    "    'bootstrap': [True, False],\n",
    "    'warm_start': [True, False],\n",
    "    'ccp_alpha': (10 ** -5, 1),\n",
    "}\n",
    "\n",
    "found_params = kfold_random_search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    RandomForestClassifier,\n",
    "    accuracy_score,\n",
    "    param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False,\n",
      " 'ccp_alpha': 1e-05,\n",
      " 'criterion': 'entropy',\n",
      " 'max_depth': 100,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_impurity_decrease': 1e-05,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 1e-05,\n",
      " 'n_estimators': 1000,\n",
      " 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(found_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.50      0.33      0.40         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.50      0.33      0.40         3\n",
      "           7       0.50      1.00      0.67         3\n",
      "           8       0.67      0.67      0.67         3\n",
      "           9       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.57      0.63      0.58        30\n",
      "weighted avg       0.57      0.63      0.58        30\n",
      "\n",
      "Grid search model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.50      0.67      0.57         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       0.50      1.00      0.67         3\n",
      "           8       1.00      0.33      0.50         3\n",
      "           9       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.81      0.73      0.72        30\n",
      "weighted avg       0.81      0.73      0.72        30\n",
      "\n",
      "Rand search model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      0.33      0.50         3\n",
      "           3       0.50      0.67      0.57         3\n",
      "           4       0.50      1.00      0.67         3\n",
      "           5       1.00      0.33      0.50         3\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       0.60      1.00      0.75         3\n",
      "           8       1.00      0.33      0.50         3\n",
      "           9       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.81      0.67      0.65        30\n",
      "weighted avg       0.81      0.67      0.65        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели.\n",
    "# Протестируйте модель на x_test, y_test (accuracy, матрица ошибок).\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 2.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "new_rand_model = RandomForestClassifier(random_state=1, **found_params)\n",
    "new_rand_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print('Base model')\n",
    "y_pred = base_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print('Grid search model')\n",
    "y_pred = new_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print('Rand search model')\n",
    "y_pred = new_rand_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Доп. задание (опционально)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Bayesian optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените байесовскую оптимизацию для поиска гиперпараметров.\n",
    "В качестве алгоритма используйте `BayesSearchCV` из пакета `scikit-optimize`.\n",
    "\n",
    "Сложность: почти бесплатный балл.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-optimize\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': (100, 1000, 'log-uniform'),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_leaf': (1, 10 ** 4, 'log-uniform'),\n",
    "    'min_weight_fraction_leaf': (10 ** -5, 0.1, 'log-uniform'),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_impurity_decrease': (10 ** -5, 1, 'log-uniform'),\n",
    "    'max_depth': (10, 100, 'log-uniform'),\n",
    "    'bootstrap': [True, False],\n",
    "    'warm_start': [True, False],\n",
    "    'ccp_alpha': (10 ** -5, 1, 'log-uniform'),\n",
    "}\n",
    "\n",
    "# 1. Инстанцируйте BayesSearchCV.\n",
    "RandomForestClassifier(random_state=1).score\n",
    "opt = BayesSearchCV(\n",
    "    RandomForestClassifier(random_state=1),\n",
    "    param_space,\n",
    "    n_iter=N_ITERS,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# 2. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "t1 = time()\n",
    "opt.fit(x_train, y_train)\n",
    "t1 = time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время работы: 91.39804530143738\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.05612051514265293,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 11,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_impurity_decrease': 0.00015077907479196478,\n",
      " 'min_samples_leaf': 7,\n",
      " 'min_weight_fraction_leaf': 0.002460522908273142,\n",
      " 'n_estimators': 822,\n",
      " 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "# 3. Выведите найденные значения гиперпараметров и время работы.\n",
    "print(f'Время работы: {t1}')\n",
    "params = dict(opt.best_params_)\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.50      0.33      0.40         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.50      0.33      0.40         3\n",
      "           7       0.50      1.00      0.67         3\n",
      "           8       0.67      0.67      0.67         3\n",
      "           9       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.57      0.63      0.58        30\n",
      "weighted avg       0.57      0.63      0.58        30\n",
      "\n",
      "Grid search model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.50      0.67      0.57         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       0.50      1.00      0.67         3\n",
      "           8       1.00      0.33      0.50         3\n",
      "           9       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.81      0.73      0.72        30\n",
      "weighted avg       0.81      0.73      0.72        30\n",
      "\n",
      "Rand search model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      0.33      0.50         3\n",
      "           3       0.50      0.67      0.57         3\n",
      "           4       0.50      1.00      0.67         3\n",
      "           5       1.00      0.33      0.50         3\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       0.60      1.00      0.75         3\n",
      "           8       1.00      0.33      0.50         3\n",
      "           9       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.81      0.67      0.65        30\n",
      "weighted avg       0.81      0.67      0.65        30\n",
      "\n",
      "skopt search model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.50      0.67      0.57         3\n",
      "           3       0.67      0.67      0.67         3\n",
      "           4       0.60      1.00      0.75         3\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       0.50      1.00      0.67         3\n",
      "           8       0.50      0.33      0.40         3\n",
      "           9       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.73      0.67      0.66        30\n",
      "weighted avg       0.73      0.67      0.66        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели.\n",
    "# Протестируйте модель на x_test, y_test (accuracy, матрица ошибок).\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 2.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "opt_model = RandomForestClassifier(random_state=1, **dict(opt.best_params_))\n",
    "opt_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print('Base model')\n",
    "y_pred = base_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print('Grid search model')\n",
    "y_pred = new_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print('Rand search model')\n",
    "y_pred = new_rand_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print('skopt search model')\n",
    "y_pred = opt_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssau3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
