{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from abc import abstractmethod\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))\n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))\n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_preds_correct(your_preds, sklearn_preds) -> bool:\n",
    "    return np.abs(your_preds - sklearn_preds).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_probs_correct(your_probs, sklearn_probs) -> bool:\n",
    "    return np.abs(your_probs - sklearn_probs).mean() < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не изменяйте код этого класса!\n",
    "class NaiveBayes:\n",
    "    def __init__(self, n_classes):\n",
    "        self.n_classes = n_classes\n",
    "        self.params = dict()\n",
    "\n",
    "    # --- PREDICTION ---\n",
    "\n",
    "    def predict(self, x, return_probs=False):\n",
    "        \"\"\"\n",
    "        x - np.array размерности [N, dim], \n",
    "        где N - количество экземпляров данных, \n",
    "        dim -размерность одного экземпляра (количество признаков).\n",
    "\n",
    "        Возвращает np.array размерности [N], содержащий номера классов для\n",
    "        соответствующих экземпляров.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for sample in x:\n",
    "            preds.append(\n",
    "                self.predict_single(sample, return_probs=return_probs)\n",
    "            )\n",
    "\n",
    "        if return_probs:\n",
    "            return np.array(preds, dtype='float32')\n",
    "\n",
    "        return np.array(preds, dtype='int32')\n",
    "\n",
    "    # Совет: вниманительно изучите файл подсказок к данной лабораторной\n",
    "    # и сопоставьте код с описанной математикой байесовского классификатора.\n",
    "    def predict_single(self, x, return_probs=False) -> int:\n",
    "        \"\"\"\n",
    "        Делает предсказание для одного экземпляра данных.\n",
    "\n",
    "        x - np.array размерности dim.\n",
    "\n",
    "        Возвращает номер класса, которому принадлежит x.\n",
    "        \"\"\"\n",
    "        assert len(\n",
    "            x.shape) == 1, f'Expected a vector, but received a tensor of shape={x.shape}'\n",
    "        marginal_prob = self.compute_marginal_probability(\n",
    "            x)  # P(x) - безусловная вероятность появления x\n",
    "\n",
    "        probs = []\n",
    "        for c in range(self.n_classes):                 # c - номер класса\n",
    "            # P(c) - априорная вероятность (вероятность появления класса)\n",
    "            prior = self.compute_prior(c)\n",
    "            # P(x|c) - вероятность появления x в предположении, что он принаждлежит c\n",
    "            likelihood = self.compute_likelihood(x, c)\n",
    "\n",
    "            # Используем теорему Байесса для просчёта условной вероятности P(c|x)\n",
    "            # P(c|x) = P(c) * P(x|c) / P(x)\n",
    "            prob = prior * likelihood / marginal_prob\n",
    "            probs.append(prob)\n",
    "\n",
    "        if return_probs:\n",
    "            return probs\n",
    "\n",
    "        return np.argmax(probs)\n",
    "\n",
    "    # Вычисляет P(x) - безусловная вероятность появления x.\n",
    "    @abstractmethod\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        pass\n",
    "\n",
    "    # Вычисляет P(c) - априорная вероятность появления класса c.\n",
    "    @abstractmethod\n",
    "    def compute_prior(self, c) -> float:\n",
    "        pass\n",
    "\n",
    "    # Вычисляет P(x|c) - вероятность наблюдения экземпляра x в предположении, что он принаждлежит c.\n",
    "    @abstractmethod\n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        pass\n",
    "\n",
    "    # --- FITTING ---\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self._estimate_prior(y)\n",
    "        self._estimate_params(x, y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _estimate_prior(self, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _estimate_params(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Наивный классификатор Байеса: гауссово распределение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите недостающий код, создайте и обучите модель.\n",
    "\n",
    "Пункты оценки:\n",
    "\n",
    "1. совпадение предсказанных классов с оными у модели sklearn. Для проверки совпадения используйте функцию `assert_preds_correct`.\n",
    "2. совпадение значений предсказанных вероятностей принадлежности классами с оными у модели sklearn. Значения вероятностей считаются равными, если функция `assert_probs_correct` возвращает True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(C_k|x) = P(x|theta) * P(C_k) / P(x)\n",
    "\n",
    "class NaiveGauss(NaiveBayes):\n",
    "\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        # Вычисляет P(x)\n",
    "        # Для просчёта безусловной вероятности используйте\n",
    "        # методы compute_prior и compute_likelihood.\n",
    "        # Напишите свой код здесь\n",
    "        p_a = 0\n",
    "        for c, _ in enumerate(self.params['stats']):\n",
    "            p_a += self.compute_prior(c) * self.compute_likelihood(x, c)\n",
    "        return p_a\n",
    "\n",
    "    def compute_prior(self, c: int) -> float:\n",
    "        # Вычисляет P(c)\n",
    "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
    "            f\"Sum of prior probabilities must be equal to 1, but is {sum(self.params['prior'])}\"\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        return self.params['prior'][c]\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian_func(x, avg, disp):\n",
    "        return (\n",
    "            (1 / np.sqrt(2 * np.pi * np.pow(disp, 2))) *\n",
    "            np.exp(\n",
    "                (-1) * (np.pow(x - avg, 2) /\n",
    "                        (2 * np.pow(disp, 2)))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_likelihood(self, x, c: int) -> float:\n",
    "        # Вычисляет P(x|c)\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        final_likelihood = None\n",
    "        for x_pos, feature_stat in enumerate(self.params['stats'][c]):\n",
    "            avg, disp = feature_stat\n",
    "            if final_likelihood is None:\n",
    "                final_likelihood = self.gaussian_func(x[x_pos], avg, disp)\n",
    "            else:\n",
    "                final_likelihood *= self.gaussian_func(x[x_pos], avg, disp)\n",
    "        return final_likelihood\n",
    "\n",
    "    # --- FITTING ---\n",
    "\n",
    "    def _estimate_prior(self, y: np.ndarray) -> None:\n",
    "        total = y.shape[0]\n",
    "        prior_probs = []\n",
    "        for cls in sorted(set(y)):\n",
    "            prior_probs.append(len(y[np.where(y == cls)]) / total)\n",
    "        self.params['prior'] = prior_probs\n",
    "\n",
    "    def _estimate_params(\n",
    "        self,\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> None:\n",
    "        classes_feature_stats = []\n",
    "        for cls in set(y):\n",
    "            subset = x[np.where(y == cls)]\n",
    "            cls_feture_stats = []\n",
    "            for x_features in range(subset.shape[1]):\n",
    "                feature_slice = subset[:, x_features]\n",
    "                cls_feture_stats.append(\n",
    "                    (np.mean(feature_slice), np.std(feature_slice)))\n",
    "            classes_feature_stats.append(tuple(cls_feture_stats))\n",
    "        self.params['stats'] = tuple(classes_feature_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = NaiveGauss(len(set(y_train)))\n",
    "ng.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "ng = NaiveGauss(len(set(y_train)))\n",
    "ng.fit(x_train.copy(), y_train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        23\n",
      "           2       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "print(classification_report(y_test, ng.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assert_preds_correct(ng.predict(x_test), skng.predict(x_test))=np.True_\n",
      "assert_probs_correct(ng.predict(x_test, True), skng.predict_proba(x_test))=np.True_\n"
     ]
    }
   ],
   "source": [
    "# Сравните вашу модель с аналогом sklearn (GaussianNB)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "skng = GaussianNB()\n",
    "skng.fit(x_train, y_train)\n",
    "\n",
    "print(f'{assert_preds_correct(ng.predict(x_test), skng.predict(x_test))=}')\n",
    "print(f'{assert_probs_correct(ng.predict(x_test, True), skng.predict_proba(x_test))=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Доп. задания (любое на выбор, опционально)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Упрощение наивного классификатора Байеса для гауссова распределения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберите из класса NaiveBayes 'лишние' вычисления и удалите код, что соответствует этим вычислениям. Под 'лишним' подразумеваются вещи, что не влияют на итоговое решение о принадлежности классу (значения вероятностей при этом могу стать некорректными, но в данном задании это допустимо).\n",
    "\n",
    "Напишите в клетке ниже код упрощенного 'классификатора Гаусса' и убедитесь, что его ответы (не значения вероятностей) совпадают с ответами классификатора из задания 1. Для сравнения ответов используйте функцию `assert_preds_correct`.\n",
    "\n",
    "Указание: работайте в предположении, что классы равновероятны.\n",
    "\n",
    "Подсказка: упростить необходимо метод `predict_single`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишите обновленный код модели здесь\n",
    "\n",
    "# Не изменяйте код этого класса!\n",
    "class NaiveBayes:\n",
    "    def __init__(self, n_classes):\n",
    "        self.n_classes = n_classes\n",
    "        self.params = dict()\n",
    "\n",
    "    # --- PREDICTION ---\n",
    "\n",
    "    def predict(self, x, return_probs=False):\n",
    "        \"\"\"\n",
    "        x - np.array размерности [N, dim], \n",
    "        где N - количество экземпляров данных, \n",
    "        dim -размерность одного экземпляра (количество признаков).\n",
    "\n",
    "        Возвращает np.array размерности [N], содержащий номера классов для\n",
    "        соответствующих экземпляров.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for sample in x:\n",
    "            preds.append(\n",
    "                self.predict_single(sample, return_probs=return_probs)\n",
    "            )\n",
    "\n",
    "        if return_probs:\n",
    "            return np.array(preds, dtype='float32')\n",
    "\n",
    "        return np.array(preds, dtype='int32')\n",
    "\n",
    "    # Совет: вниманительно изучите файл подсказок к данной лабораторной\n",
    "    # и сопоставьте код с описанной математикой байесовского классификатора.\n",
    "    def predict_single(self, x, return_probs=False) -> int:\n",
    "        \"\"\"\n",
    "        Делает предсказание для одного экземпляра данных.\n",
    "\n",
    "        x - np.array размерности dim.\n",
    "\n",
    "        Возвращает номер класса, которому принадлежит x.\n",
    "        \"\"\"\n",
    "        assert len(\n",
    "            x.shape) == 1, f'Expected a vector, but received a tensor of shape={x.shape}'\n",
    "\n",
    "        probs = []\n",
    "        for c in range(self.n_classes):                 # c - номер класса\n",
    "            # P(c) - априорная вероятность (вероятность появления класса)\n",
    "            # P(x|c) - вероятность появления x в предположении, что он принаждлежит c\n",
    "            likelihood = self.compute_likelihood(x, c)\n",
    "\n",
    "            # Используем теорему Байесса для просчёта условной вероятности P(c|x)\n",
    "            # P(c|x) = P(c) * P(x|c) / P(x)\n",
    "            prob = likelihood\n",
    "            probs.append(prob)\n",
    "\n",
    "        if return_probs:\n",
    "            return probs\n",
    "\n",
    "        return np.argmax(probs)\n",
    "\n",
    "    # Вычисляет P(x) - безусловная вероятность появления x.\n",
    "    @abstractmethod\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        pass\n",
    "\n",
    "    # Вычисляет P(c) - априорная вероятность появления класса c.\n",
    "    @abstractmethod\n",
    "    def compute_prior(self, c) -> float:\n",
    "        pass\n",
    "\n",
    "    # Вычисляет P(x|c) - вероятность наблюдения экземпляра x в предположении, что он принаждлежит c.\n",
    "    @abstractmethod\n",
    "    def compute_likelihood(self, x, c) -> float:\n",
    "        pass\n",
    "\n",
    "    # --- FITTING ---\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self._estimate_prior(y)\n",
    "        self._estimate_params(x, y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _estimate_prior(self, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _estimate_params(self, x, y):\n",
    "        pass\n",
    "\n",
    "\n",
    "class NaiveGauss(NaiveBayes):\n",
    "\n",
    "    def compute_marginal_probability(self, x) -> float:\n",
    "        # Вычисляет P(x)\n",
    "        # Для просчёта безусловной вероятности используйте\n",
    "        # методы compute_prior и compute_likelihood.\n",
    "        # Напишите свой код здесь\n",
    "        p_a = 0\n",
    "        for c, _ in enumerate(self.params['stats']):\n",
    "            p_a += self.compute_prior(c) * self.compute_likelihood(x, c)\n",
    "        return p_a\n",
    "\n",
    "    def compute_prior(self, c: int) -> float:\n",
    "        # Вычисляет P(c)\n",
    "        assert abs(sum(self.params['prior']) - 1.0) < 1e-3, \\\n",
    "            f\"Sum of prior probabilities must be equal to 1, but is {sum(self.params['prior'])}\"\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        return self.params['prior'][c]\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian_func(x, avg, disp):\n",
    "        return (\n",
    "            (1 / np.sqrt(2 * np.pi * np.pow(disp, 2))) *\n",
    "            np.exp(\n",
    "                (-1) * (np.pow(x - avg, 2) /\n",
    "                        (2 * np.pow(disp, 2)))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_likelihood(self, x, c: int) -> float:\n",
    "        # Вычисляет P(x|c)\n",
    "        assert c < self.n_classes, f'Class index must be < {self.n_classes}, but received {c}.'\n",
    "        final_likelihood = None\n",
    "        for x_pos, feature_stat in enumerate(self.params['stats'][c]):\n",
    "            avg, disp = feature_stat\n",
    "            if final_likelihood is None:\n",
    "                final_likelihood = self.gaussian_func(x[x_pos], avg, disp)\n",
    "            else:\n",
    "                final_likelihood *= self.gaussian_func(x[x_pos], avg, disp)\n",
    "        return final_likelihood\n",
    "\n",
    "    # --- FITTING ---\n",
    "\n",
    "    def _estimate_prior(self, y: np.ndarray) -> None:\n",
    "        total = y.shape[0]\n",
    "        prior_probs = []\n",
    "        for cls in sorted(set(y)):\n",
    "            prior_probs.append(len(y[np.where(y == cls)]) / total)\n",
    "        self.params['prior'] = prior_probs\n",
    "\n",
    "    def _estimate_params(\n",
    "        self,\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> None:\n",
    "        classes_feature_stats = []\n",
    "        for cls in set(y):\n",
    "            subset = x[np.where(y == cls)]\n",
    "            cls_feture_stats = []\n",
    "            for x_features in range(subset.shape[1]):\n",
    "                feature_slice = subset[:, x_features]\n",
    "                cls_feture_stats.append(\n",
    "                    (np.mean(feature_slice), np.std(feature_slice)))\n",
    "            classes_feature_stats.append(tuple(cls_feture_stats))\n",
    "        self.params['stats'] = tuple(classes_feature_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель\n",
    "ng1 = NaiveGauss(len(set(y_train)))\n",
    "ng1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        23\n",
      "           2       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество модели\n",
    "print(classification_report(y_test, ng1.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assert_preds_correct(ng1.predict(x_test), ng.predict(x_test))=np.True_\n",
      "assert_probs_correct(ng1.predict(x_test, True), ng.predict(x_test, True))=np.False_\n"
     ]
    }
   ],
   "source": [
    "# Сравните вашу модель с моделью из задания 1\n",
    "print(f'{assert_preds_correct(ng1.predict(x_test), ng.predict(x_test))=}')\n",
    "print(f'{assert_probs_correct(ng1.predict(x_test, True), ng.predict(x_test, True))=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объясните в комментариях к этой клетке суть проделанных изменений: почему удаленный код является лишним?\n",
    "\n",
    "1. Убрано умножение на prior\n",
    "\n",
    "   Исходя из предположения, что каждый класс равновероятен, следует что априорная вероятность для каждого класса будет одинакова.\n",
    "\n",
    "   Это в свою очередь означает, что на конечную вероятность данная веростность никакого влияния оказывать не будет, соотетственно её можно исключить из подсчёта, максимальная вероятность принадлежности останется у того же класса\n",
    "\n",
    "2. Убрано деление на marginal_prob\n",
    "\n",
    "   Эта операция выступала в качестве нормализации данных и приведении к формату [0..1]\n",
    "\n",
    "   В нашем же случае необходимо предсказать класс, а не его вероятность, соотетственно что без деления, что с делением, мы выбираем максимальное просчитанное значение, на основе чего и делаем вывод - что это за класс.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssau3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
