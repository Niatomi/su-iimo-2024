{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практическое задание 8\n",
    "\n",
    "## Вариант\n",
    "\n",
    "### Классификаторы:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"SVM linear\",\n",
    "  \"Linear Discriminant Analysis\",\n",
    "  \"Random Forest\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13602/267608156.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[name] = mmsx[:, idx]\n"
     ]
    }
   ],
   "source": [
    "# 1. Загрузить датасет WINE.\n",
    "wine = load_wine(as_frame=True)\n",
    "X = wine.data\n",
    "Y = wine.target\n",
    "\n",
    "mmsx = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "for idx, name in enumerate(wine.data):\n",
    "    X[name] = mmsx[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.167984</td>\n",
       "      <td>0.598930</td>\n",
       "      <td>0.304124</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.757384</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.633106</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.567766</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.560526</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.700535</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.611814</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.757098</td>\n",
       "      <td>0.375427</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.646933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.463158</td>\n",
       "      <td>0.381423</td>\n",
       "      <td>0.598930</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.812287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073260</td>\n",
       "      <td>0.144080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177866</td>\n",
       "      <td>0.433155</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.293478</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.495268</td>\n",
       "      <td>0.334471</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.578755</td>\n",
       "      <td>0.547076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.274704</td>\n",
       "      <td>0.759358</td>\n",
       "      <td>0.922680</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.400844</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.425868</td>\n",
       "      <td>0.146758</td>\n",
       "      <td>0.398374</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.134094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.203557</td>\n",
       "      <td>0.673797</td>\n",
       "      <td>0.283505</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.328076</td>\n",
       "      <td>0.300341</td>\n",
       "      <td>0.357724</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.654066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.155263</td>\n",
       "      <td>0.247036</td>\n",
       "      <td>0.491979</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0.168089</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.047789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.739474</td>\n",
       "      <td>0.667984</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.458763</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.282759</td>\n",
       "      <td>0.103376</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.659556</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.135531</td>\n",
       "      <td>0.144080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.498024</td>\n",
       "      <td>0.631016</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.046414</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.123028</td>\n",
       "      <td>0.392491</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.201465</td>\n",
       "      <td>0.286733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.389474</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.331551</td>\n",
       "      <td>0.510309</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.420690</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.337539</td>\n",
       "      <td>0.141638</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.842491</td>\n",
       "      <td>0.281027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "18   0.831579    0.167984  0.598930           0.304124   0.413043   \n",
       "2    0.560526    0.320158  0.700535           0.412371   0.336957   \n",
       "151  0.463158    0.381423  0.598930           0.587629   0.456522   \n",
       "8    1.000000    0.177866  0.433155           0.175258   0.293478   \n",
       "127  0.200000    0.274704  0.759358           0.922680   0.239130   \n",
       "..        ...         ...       ...                ...        ...   \n",
       "26   0.621053    0.203557  0.673797           0.283505   0.250000   \n",
       "94   0.155263    0.247036  0.491979           0.381443   0.304348   \n",
       "156  0.739474    0.667984  0.545455           0.458763   0.206522   \n",
       "161  0.700000    0.498024  0.631016           0.484536   0.402174   \n",
       "104  0.389474    0.195652  0.331551           0.510309   0.163043   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "18        0.800000    0.757384              0.358491         0.457413   \n",
       "2         0.627586    0.611814              0.320755         0.757098   \n",
       "151       0.172414    0.215190              0.207547         0.268139   \n",
       "8         0.627586    0.556962              0.301887         0.495268   \n",
       "127       0.396552    0.400844              0.849057         0.425868   \n",
       "..             ...         ...                   ...              ...   \n",
       "26        0.644828    0.548523              0.396226         0.328076   \n",
       "94        0.703448    0.405063              0.075472         0.296530   \n",
       "156       0.282759    0.103376              0.660377         0.362776   \n",
       "161       0.293103    0.046414              0.698113         0.123028   \n",
       "104       0.420690    0.333333              0.358491         0.337539   \n",
       "\n",
       "     color_intensity       hue  od280/od315_of_diluted_wines   proline  \n",
       "18          0.633106  0.609756                      0.567766  1.000000  \n",
       "2           0.375427  0.447154                      0.695971  0.646933  \n",
       "151         0.812287  0.000000                      0.073260  0.144080  \n",
       "8           0.334471  0.487805                      0.578755  0.547076  \n",
       "127         0.146758  0.398374                      0.428571  0.134094  \n",
       "..               ...       ...                           ...       ...  \n",
       "26          0.300341  0.357724                      0.714286  0.654066  \n",
       "94          0.168089  0.552846                      0.619048  0.047789  \n",
       "156         0.659556  0.073171                      0.135531  0.144080  \n",
       "161         0.392491  0.390244                      0.201465  0.286733  \n",
       "104         0.141638  0.455285                      0.842491  0.281027  \n",
       "\n",
       "[124 rows x 13 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Подготовить выборки: обучающую 70% и тестовую 30%.\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.3,\n",
    "    stratify=Y)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flavanoids', 'proline']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Для указанных в задании классификаторов с использованием обучающей выборки выбрать 2 компоненты вектора признаков (2 признака), обеспечивающие наилучшее качество классификации.\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest,\n",
    "    f_classif\n",
    ")\n",
    "\n",
    "\n",
    "def get_best_features(x_train, y_train):\n",
    "    x_train_selected = SelectKBest(\n",
    "        f_classif, k=2).fit_transform(x_train, y_train)\n",
    "    xt = x_train.copy().reset_index()\n",
    "    feature_names = []\n",
    "    for val in x_train_selected[0]:\n",
    "        for name in x_train.columns:\n",
    "            if xt[name][0] == val:\n",
    "                feature_names.append(name)\n",
    "                break\n",
    "    return feature_names\n",
    "\n",
    "\n",
    "cn = get_best_features(x_train, y_train)\n",
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Получить оценку качества классификации с использованием тестовой выборки.\n",
    "x_train, x_test = x_train[cn], x_test[cn]\n",
    "CLS_REPORT = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      0.86      0.92        21\n",
      "           2       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.94      0.95      0.94        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM linear\n",
    "svm_clf = svm.SVC(kernel='linear', C=1, max_iter=20000)\n",
    "svm_clf.fit(x_train, y_train)\n",
    "print(classification_report(y_test, svm_clf.predict(x_test)))\n",
    "CLS_REPORT.append(('SVM', svm_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      0.86      0.92        21\n",
      "           2       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.94      0.95      0.94        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "lda_clf = LDA(n_components=1)\n",
    "_ = lda_clf.fit_transform(x_train, y_train)\n",
    "print(classification_report(y_test, lda_clf.predict(x_test)))\n",
    "CLS_REPORT.append(('LDA', lda_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        18\n",
      "           1       0.94      0.76      0.84        21\n",
      "           2       0.82      0.93      0.88        15\n",
      "\n",
      "    accuracy                           0.89        54\n",
      "   macro avg       0.89      0.90      0.89        54\n",
      "weighted avg       0.89      0.89      0.89        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=30)\n",
    "rf_clf.fit(x_train, y_train)\n",
    "print(classification_report(y_test, rf_clf.predict(x_test)))\n",
    "CLS_REPORT.append(('RandomForestClassifier', rf_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выбранные признаки: ['flavanoids', 'proline']\n",
      "---- SVM ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      0.86      0.92        21\n",
      "           2       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.94      0.95      0.94        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n",
      "---- ------ ----\n",
      "---- LDA ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      0.86      0.92        21\n",
      "           2       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.94      0.95      0.94        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n",
      "---- ------ ----\n",
      "---- RandomForestClassifier ----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        18\n",
      "           1       0.94      0.76      0.84        21\n",
      "           2       0.82      0.93      0.88        15\n",
      "\n",
      "    accuracy                           0.89        54\n",
      "   macro avg       0.89      0.90      0.89        54\n",
      "weighted avg       0.89      0.89      0.89        54\n",
      "\n",
      "---- ------ ----\n",
      "\n",
      "---- Вывод ----\n",
      "\n",
      "Наилучшую точность продемонстрировали SVM и LDA классификаторы\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Сравнить выбранные признаки для каждого из классификаторов и сделать вывод.\n",
    "print(f'Выбранные признаки: {cn}')\n",
    "for name, clf in CLS_REPORT:\n",
    "    print(f'---- {name} ----')\n",
    "    print(classification_report(y_test, clf.predict(x_test)))\n",
    "    print(f'---- ------ ----')\n",
    "print()\n",
    "print('---- Вывод ----')\n",
    "print(\n",
    "    f\"\"\"\n",
    "Наилучшую точность продемонстрировали SVM и LDA классификаторы\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssau3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
