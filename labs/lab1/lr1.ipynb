{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))\n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))\n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        rng = np.random.default_rng(seed=0)\n",
    "        self.w = rng.normal(size=(dim, 1)) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "\n",
    "    def predict(self, x, probs=False):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "\n",
    "        x = x.dot(self.w) + self.b  # logits\n",
    "        p = sigmoid(x)  # probabilities\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "\n",
    "    def fit(self, x, y, iters=1000, lr=0.01):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        # y - np.array размернсоти [N]\n",
    "        #     Массив меток (правильных ответов).\n",
    "        assert len(x) == len(y), \\\n",
    "            \"Количество экземпляров в массиве X не равно количеству меток в массиве Y. \" + \\\n",
    "            f\"Полученные размеры: len(X) = {len(x)}, len(Y) = {len(y)}.\"\n",
    "        assert x.shape[1] == self.w.shape[0], \\\n",
    "            \"Размерность экземпляров данных не соответствует ожидаемой: \" + \\\n",
    "            f\"ожидалось x.shape[1]={self.w.shape[0]}, но было получено x.shape[1]={x.shape[1]}\"\n",
    "        # Алгоритм градиентного спуска.\n",
    "        # Минимизируется бинарная кросс-энтропия.\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Применение логистической регрессии (несбалансированные данные)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Создание и обучение логистической регрессии\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указание: производить нормализацию данных не нужно, это часть задания.\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x7f945c507fa0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте модель логистической регрессии и обучите её, используя метод fit.\n",
    "lr = LogisticRegression(x_train.shape[1])\n",
    "lr.fit(x_train, y_train, iters=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318181818181818"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получите предсказания на тестовой выборке и оцените точность модели,\n",
    "# используя accuracy_score из пакета SciKit-Learn.\n",
    "accuracy_score(\n",
    "    y_test,\n",
    "    lr.predict(x_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Анализ качества модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Допишите класс \"глупого классификатора\", что всегда предсказывает класс `0`.\n",
    "\n",
    "class DummyClassifier:\n",
    "    def __init__(self, dt=np.float32):\n",
    "        self.dt = dt\n",
    "\n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Должен возвращаться массив N предсказаний\n",
    "        return np.zeros(x.shape[0], dtype=self.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцените точность \"глупого классификатора\", объясните результат.\n",
    "dc = DummyClassifier()\n",
    "assert x_test.shape[0] == dc.predict(x_test).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте дополнительные метрики (f1-score, recall, precision) из пакета sklearn для анализа \"глупого классификатора\".\n",
    "\n",
    "\n",
    "def get_stats(model, x_test, y_test, avg='binary') -> tuple:\n",
    "    m = model\n",
    "    y_pred = m.predict(x_test).astype(np.bool)\n",
    "    f1 = f1_score(y_test, y_pred, average=avg)\n",
    "    recall = recall_score(y_test, y_pred, average=avg)\n",
    "    precision = precision_score(y_test, y_pred, average=avg)\n",
    "    print(f'{f1=}')\n",
    "    print(f'{recall=}')\n",
    "    print(f'{precision=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=np.float64(0.0)\n",
      "recall=np.float64(0.0)\n",
      "precision=np.float64(0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nia/.pyenv/versions/3.10.14/envs/ssau3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "get_stats(dc, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=np.float64(0.6341463414634146)\n",
      "recall=np.float64(0.65)\n",
      "precision=np.float64(0.6190476190476191)\n"
     ]
    }
   ],
   "source": [
    "# Используя те же метрики, проанализируйте обученную вами модель логистической регрессии.\n",
    "get_stats(lr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Общие термины\n",
      "Глупый классификатор - DC\n",
      "Корректный классификатор - LR\n",
      "\n",
      "\n",
      "# Precision\n",
      "\n",
      "DC классификатор нашёл 0 единиц\n",
      "LR классификатор нашёл 21 единиц\n",
      "\n",
      "Из которых правильно предсказанные:\n",
      "Для DC: 0\n",
      "Для LR: 13\n",
      "\n",
      "Соответственно метрика Precision:\n",
      "DC: dc_correct_ones/dc_ones=0\n",
      "LR: lr_correct_ones/lr_ones=0.6190476190476191\n",
      "\n",
      "\n",
      "# Recall\n",
      "\n",
      "Всего меток с единицей 20\n",
      "\n",
      "Из которых правильно предсказанные:\n",
      "Для DC: 0\n",
      "Для LR: 13\n",
      "\n",
      "Соответственно метрика Recall:\n",
      "DC: dc_recall_ones/total_ones=0.0\n",
      "LR: lr_recall_ones/total_ones=0.65\n",
      "\n",
      "\n",
      "# F1 \n",
      "DC: (2 * dc_precision * dc_recall) / (dc_precision + dc_recall)=0\n",
      "LR: (2 * lr_precision * lr_recall) / (lr_precision + lr_recall)=0.6341463414634146\n",
      "\n",
      "\n",
      "# Общий вывод\n",
      "Так как вышеописанные метрики расчитываются относительно единичного класса,\n",
      "то для DC классификатора метрики равны нулю, так как модель предсказывает всегда ноль\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Объясните результат, описав его комментариями в этой клетке.\n",
    "total_ones = 0\n",
    "\n",
    "dc_pred = dc.predict(x_test)\n",
    "dc_ones = 0\n",
    "dc_correct_ones = 0\n",
    "dc_recall_ones = 0\n",
    "\n",
    "lr_pred = lr.predict(x_test)\n",
    "lr_ones = 0\n",
    "lr_correct_ones = 0\n",
    "lr_recall_ones = 0\n",
    "\n",
    "for dc_y_pred, lr_y_pred, y_real in zip(dc_pred, lr_pred, y_test):\n",
    "    if dc_y_pred == 1:\n",
    "        dc_ones += 1\n",
    "        if dc_y_pred == y_real:\n",
    "            dc_correct_ones += 1\n",
    "    if lr_y_pred == 1:\n",
    "        lr_ones += 1\n",
    "        if lr_y_pred == y_real:\n",
    "            lr_correct_ones += 1\n",
    "    if y_real == 1:\n",
    "        total_ones += 1\n",
    "        if dc_y_pred == y_real:\n",
    "            dc_recall_ones += 1\n",
    "        if lr_y_pred == y_real:\n",
    "            lr_recall_ones += 1\n",
    "\n",
    "dc_precision = 0\n",
    "lr_precision = lr_correct_ones/lr_ones\n",
    "\n",
    "dc_recall = 0\n",
    "lr_recall = lr_recall_ones/total_ones\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "# Общие термины\n",
    "Глупый классификатор - DC\n",
    "Корректный классификатор - LR\n",
    "\n",
    "\n",
    "# Precision\n",
    "\n",
    "DC классификатор нашёл {dc_ones} единиц\n",
    "LR классификатор нашёл {lr_ones} единиц\n",
    "\n",
    "Из которых правильно предсказанные:\n",
    "Для DC: {dc_correct_ones}\n",
    "Для LR: {lr_correct_ones}\n",
    "\n",
    "Соответственно метрика Precision:\n",
    "DC: dc_correct_ones/dc_ones=0\n",
    "LR: {lr_correct_ones/lr_ones=}\n",
    "\n",
    "\n",
    "# Recall\n",
    "\n",
    "Всего меток с единицей {total_ones}\n",
    "\n",
    "Из которых правильно предсказанные:\n",
    "Для DC: {dc_recall_ones}\n",
    "Для LR: {lr_recall_ones}\n",
    "\n",
    "Соответственно метрика Recall:\n",
    "DC: {dc_recall_ones/total_ones=}\n",
    "LR: {lr_recall_ones/total_ones=}\n",
    "\n",
    "\n",
    "# F1 \n",
    "DC: (2 * dc_precision * dc_recall) / (dc_precision + dc_recall)=0\n",
    "LR: {(2 * lr_precision * lr_recall) / (lr_precision + lr_recall)=}\n",
    "\n",
    "\n",
    "# Общий вывод\n",
    "Так как вышеописанные метрики расчитываются относительно единичного класса,\n",
    "то для DC классификатора метрики равны нулю, так как модель предсказывает всегда ноль\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Анализ набора данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float32(0.0): 200, np.float32(1.0): 20}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посчитайте количество экземпляров данных для каждого класса.\n",
    "def count_classes(y_test):\n",
    "    total_count = {}\n",
    "    for y in set(y_test):\n",
    "        total_count[y] = len(y_test[np.where(\n",
    "            y_test == y\n",
    "        )])\n",
    "    return total_count\n",
    "\n",
    "\n",
    "count_classes(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предложите способ улучшения качества модели.\n",
    "# Подсказка: добавление дубликатов в данные.\n",
    "# Указание: не изменяйте тестовую выборку.\n",
    "def balance_data(\n",
    "    x_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    shuffle: bool = False,\n",
    "    seed: int = None\n",
    ") -> tuple[np.array, np.array]:\n",
    "    \"\"\"Досоздание данных для обучения\n",
    "\n",
    "    Args:\n",
    "        x_train (np.array размерности [N, dim]): \n",
    "            Массив входных признаков.\n",
    "        y_train (np.array размернсоти [N]): \n",
    "            Массив меток (правильных ответов).\n",
    "        shuffle (bool, optional): \n",
    "            Перемешивать данные или нет. \n",
    "            Defaults to False.\n",
    "        seed (int, optional): \n",
    "            Сид для перемешивания данных. \n",
    "            Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, np.array]:\n",
    "        Сбаланисированные массивы входных признаков и меток\n",
    "    \"\"\"\n",
    "\n",
    "    def get_intervals(ind):\n",
    "        return ind[0][0], ind[0][-1], len(ind[0])\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    xt, yt = x_train.copy(), y_train.copy()\n",
    "\n",
    "    total_count = count_classes(yt)\n",
    "    cnt = list(total_count.values())\n",
    "\n",
    "    ones_indicies = np.where(yt == 1)\n",
    "\n",
    "    low, high, _ = get_intervals(ones_indicies)\n",
    "    poses = np.random.randint(low=low, high=high, size=cnt[0] - cnt[1])\n",
    "\n",
    "    xt = np.vstack((xt, xt[poses]))\n",
    "    yt = np.hstack((yt, yt[poses]))\n",
    "\n",
    "    assert xt.shape[0] == yt.shape[0]\n",
    "\n",
    "    if shuffle:\n",
    "        idxs = np.arange(len(yt))\n",
    "        np.random.shuffle(idxs)\n",
    "        return xt[idxs], yt[idxs]\n",
    "    return xt, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x7f9401208100>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель с использованием предложенных наработок.\n",
    "xt, yt = balance_data(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    shuffle=False,\n",
    "    seed=None\n",
    ")\n",
    "bm = LogisticRegression(x_train.shape[1])\n",
    "bm.fit(xt, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=np.float64(0.6341463414634146)\n",
      "recall=np.float64(0.65)\n",
      "precision=np.float64(0.6190476190476191)\n",
      "\n",
      "f1=np.float64(0.7142857142857143)\n",
      "recall=np.float64(0.75)\n",
      "precision=np.float64(0.6818181818181818)\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics.\n",
    "# Указание: постарайтесь сбалансировать данные таким образом, чтобы новая модель была ощутимо лучше старой.\n",
    "get_stats(lr, x_test, y_test)\n",
    "print()\n",
    "get_stats(bm, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Применение логистической регрессии (нелинейные данные)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x7f940126a890>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель но на этом наборе данных.\n",
    "lr = LogisticRegression(x_train.shape[1])\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=np.float64(0.6194690265486725)\n",
      "recall=np.float64(0.7777777777777778)\n",
      "precision=np.float64(0.5147058823529411)\n"
     ]
    }
   ],
   "source": [
    "# Проанализируйте качество модели.\n",
    "get_stats(lr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: попробуйте применить на исходных данных разные нелинейные функции (sin, tanh, ...).\n",
    "# Объедините трансформированные данные с исходными (важно: количество экземпляров в x_train не должно увеличиться).\n",
    "x_train, y_train, x_test, y_test = load_data('dataset2')\n",
    "\n",
    "\n",
    "OPS = [\n",
    "    np.sin,\n",
    "    np.cos,\n",
    "    np.tan,\n",
    "]\n",
    "\n",
    "\n",
    "def apply_ops(\n",
    "    x_train: np.ndarray,\n",
    "    ops: list[np.ufunc]\n",
    ") -> np.ndarray:\n",
    "    xt = x_train.copy()\n",
    "    input_size = xt.shape[0]\n",
    "    for op in ops:\n",
    "        assert type(op) is np.ufunc\n",
    "        xt = np.hstack(\n",
    "            (xt, op(xt))\n",
    "        )\n",
    "    assert input_size == xt.shape[0]\n",
    "    return xt\n",
    "\n",
    "\n",
    "x_train = apply_ops(x_train, OPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x7f94010dff40>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте и обучите модель с использованием наработок.\n",
    "lr = LogisticRegression(x_train.shape[1])\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1=np.float64(1.0)\n",
      "recall=np.float64(1.0)\n",
      "precision=np.float64(1.0)\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics.\n",
    "# Указание: постарайтесь добиться точности в 100%!\n",
    "get_stats(lr, apply_ops(x_test, OPS), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Доп. задания (любое на выбор, опционально)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssau3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
